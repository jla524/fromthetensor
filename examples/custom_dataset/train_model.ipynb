{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80bedc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from helpers import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b75dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").resolve(strict=True).parent.parent / \"data\"\n",
    "assert data_dir.is_dir()\n",
    "\n",
    "features_path = data_dir / \"london_features.csv\"\n",
    "assert features_path.is_file()\n",
    "\n",
    "models_dir = Path(\".\").resolve(strict=True).parent.parent / \"models\"\n",
    "model_path = models_dir / \"lstm_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ea15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(features_path)\n",
    "assert not dataset.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931d7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and target, and convert them to numpy arrays\n",
    "target = np.expand_dims(dataset[\"cnt\"].values.astype(np.float32), axis=1)\n",
    "features = dataset.drop(columns=[\"cnt\"]).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513de1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences (past 24 hours to predict next)\n",
    "def create_sequences(X, y, seq_len=24):\n",
    "    xs, ys = [], []\n",
    "    for i in range(seq_len, len(X)):\n",
    "        xs.append(X[i-seq_len:i])  # (seq_len, num_features)\n",
    "        ys.append(y[i])\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2efbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 24\n",
    "features_seq, target_seq = create_sequences(features, target, seq_len)\n",
    "num_features = features_seq.shape[2]\n",
    "\n",
    "num_epochs = 100\n",
    "eval_epochs = 10\n",
    "hidden_size = 128\n",
    "learning_rate = 0.005\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb38567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8906b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(X, n_splits=5):\n",
    "    num_samples = len(X)\n",
    "    indices = np.arange(num_samples)\n",
    "    sample_size = num_samples // (n_splits + 1)\n",
    "    for i in range(1, n_splits + 1):\n",
    "        train_stop = i * sample_size\n",
    "        test_stop = min((i + 1) * sample_size, num_samples)\n",
    "        yield indices[:train_stop], indices[train_stop:test_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d17749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "full_train_idx, full_test_idx = list(time_series_split(features_seq, n_splits=1))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model.train()\n",
    "    X_train = torch.tensor(features_seq[full_train_idx], device=device)  # 3D: (batch, seq_len, features)\n",
    "    y_train = torch.tensor(target_seq[full_train_idx], device=device).squeeze(-1)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    train_losses, test_losses = [], []\n",
    "    with torch.no_grad():\n",
    "        for _, (train_idx, test_idx) in enumerate(time_series_split(features_seq, n_splits=5)):\n",
    "            X_t = torch.tensor(features_seq[train_idx], device=device)\n",
    "            y_t = torch.tensor(target_seq[train_idx], device=device).squeeze(-1)\n",
    "            pred_t = model(X_t)\n",
    "            train_losses.append(float(loss_fn(pred_t, y_t)))\n",
    "\n",
    "            X_te = torch.tensor(features_seq[test_idx], device=device)\n",
    "            y_te = torch.tensor(target_seq[test_idx], device=device).squeeze(-1)\n",
    "            pred_te = model(X_te)\n",
    "            test_losses.append(float(loss_fn(pred_te, y_te)))\n",
    "\n",
    "    avg_train_rmse = np.sqrt(np.mean(train_losses))\n",
    "    avg_test_rmse = np.sqrt(np.mean(test_losses))\n",
    "    return avg_train_rmse, avg_test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e9d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train loss 0.5281, test loss 0.5285\n",
      "epoch 20: train loss 0.3758, test loss 0.3695\n",
      "epoch 30: train loss 0.3081, test loss 0.3178\n",
      "epoch 40: train loss 0.2797, test loss 0.2875\n",
      "epoch 50: train loss 0.2655, test loss 0.2719\n",
      "epoch 60: train loss 0.2554, test loss 0.2636\n",
      "epoch 70: train loss 0.2462, test loss 0.2569\n",
      "epoch 80: train loss 0.2374, test loss 0.2492\n",
      "epoch 90: train loss 0.2415, test loss 0.2562\n",
      "epoch 100: train loss 0.2323, test loss 0.2462\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    train_model()\n",
    "    # eval loop\n",
    "    if (epoch + 1) % eval_epochs == 0:\n",
    "        train_loss, test_loss = evaluate_model()\n",
    "        print(f\"epoch {epoch + 1}: train loss {train_loss:.4f}, test loss {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2757c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir.mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d5021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromthetensor (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
