{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f62dc19-306b-418b-87c5-d18c39ed9848",
   "metadata": {},
   "source": [
    "A rough copy of https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e4f588-4d3a-454f-8d21-d2a616eaf89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4237daa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10fb2fc30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7d3ffc-6888-4a6c-b4f8-8a777a6da2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).reshape(-1, 1)\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * -math.log(10000.0) / dim_model)\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\", pos_encoding)\n",
    "\n",
    "    def __call__(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p):\n",
    "        super().__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.positional_encoder = PositionalEncoding(dim_model=dim_model, dropout_p=dropout_p, max_len=5000)\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.fc = nn.Linear(dim_model, num_tokens)\n",
    "\n",
    "    def __call__(self, source, target, target_mask=None, source_pad_mask=None, target_pad_mask=None):\n",
    "        source = self.embedding(source) * math.sqrt(self.dim_model)\n",
    "        target = self.embedding(target) * math.sqrt(self.dim_model)\n",
    "        source = self.positional_encoder(source).permute(1, 0, 2)\n",
    "        target = self.positional_encoder(target).permute(1, 0, 2)\n",
    "        transformer_out = self.transformer(\n",
    "            source,\n",
    "            target,\n",
    "            tgt_mask=target_mask,\n",
    "            src_key_padding_mask=source_pad_mask,\n",
    "            tgt_key_padding_mask=target_pad_mask,\n",
    "        )\n",
    "        out = self.fc(transformer_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_target_mask(size):\n",
    "    mask = torch.tril(torch.ones(size, size) == 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_pad_mask(matrix, pad_token):\n",
    "    return matrix == pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ba6f7e-ddf4-4824-aacc-f1d9afb6ee2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacky/repos/fromthetensor/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_random_data(n):\n",
    "    sos_token = np.array([2])\n",
    "    eos_token = np.array([3])\n",
    "    length = 8\n",
    "    data = []\n",
    "    for _ in range(n // 3):\n",
    "        X = np.concatenate((sos_token, np.ones(length), eos_token))\n",
    "        y = np.concatenate((sos_token, np.ones(length), eos_token))\n",
    "        data.append([X, y])\n",
    "    for _ in range(n // 3):\n",
    "        X = np.concatenate((sos_token, np.zeros(length), eos_token))\n",
    "        y = np.concatenate((sos_token, np.zeros(length), eos_token))\n",
    "        data.append([X, y])\n",
    "    for _ in range(n // 3):\n",
    "        X = np.zeros(length)\n",
    "        start = random.randint(0, 1)\n",
    "        X[start::2] = 1\n",
    "        y = np.zeros(length)\n",
    "        if X[-1] == 0:\n",
    "            y[0::2] = 1\n",
    "        else:\n",
    "            y[1::2] = 1\n",
    "        X = np.concatenate((sos_token, X, eos_token))\n",
    "        y = np.concatenate((sos_token, y, eos_token))\n",
    "        data.append([X, y])\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        if idx + batch_size < len(data):\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "                for seq in data[idx:idx+batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_batch_length - len(data[idx+seq_idx])\n",
    "                    data[idx+seq_idx] += [padding_token] * remaining_length\n",
    "            batches.append(np.array(data[idx:idx+batch_size]).astype(np.int64))\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_dataloader = batchify_data(generate_random_data(9000))\n",
    "valid_dataloader = batchify_data(generate_random_data(3000))\n",
    "\n",
    "model = Transformer(\n",
    "    num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.05\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921bab16-1d29-46f3-9937-1866d6a1cca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 49.13it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 308.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4907\n",
      "Validation loss: 0.3734\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:10<00:00, 53.45it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 320.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3639\n",
      "Validation loss: 0.2903\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:10<00:00, 52.27it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 233.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2973\n",
      "Validation loss: 0.2240\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 48.10it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 283.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2492\n",
      "Validation loss: 0.1739\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 48.67it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 251.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2225\n",
      "Validation loss: 0.1492\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 50.78it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 305.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2065\n",
      "Validation loss: 0.1408\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 49.00it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 322.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1957\n",
      "Validation loss: 0.1408\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 50.85it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 281.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1878\n",
      "Validation loss: 0.1234\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 50.05it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 248.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1796\n",
      "Validation loss: 0.1336\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:11<00:00, 50.91it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 247.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1766\n",
      "Validation loss: 0.1065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_loop(model, optimizer, loss_fn, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        X = torch.tensor(batch[:, 0])\n",
    "        y = torch.tensor(batch[:, 1])\n",
    "        y_input = y[:, :-1]\n",
    "        y_expected = y[:, 1:]\n",
    "        target_mask = get_target_mask(y_input.size(1))\n",
    "        pred = model(X, y_input, target_mask).permute(1, 2, 0)\n",
    "        loss = loss_fn(pred, y_expected)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.detach().item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "            X = torch.tensor(batch[:, 0], dtype=torch.long)\n",
    "            y = torch.tensor(batch[:, 1], dtype=torch.long)\n",
    "            y_input = y[:, :-1]\n",
    "            y_expected = y[:, 1:]\n",
    "            target_mask = get_target_mask(y_input.size(1))\n",
    "            pred = model(X, y_input, target_mask).permute(1, 2, 0)\n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def fit(model, optimizer, loss_fn, train_dataloader, valid_dataloader, epochs):\n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\" * 25, f\"Epoch {epoch + 1}\", \"-\" * 25)\n",
    "        train_loss = train_loop(model, optimizer, loss_fn, train_dataloader)\n",
    "        validation_loss = validation_loop(model, loss_fn, valid_dataloader)\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "fit(model, optimizer, loss_fn, train_dataloader, valid_dataloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebba209c-95d4-485f-a424-d66266c51781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Input: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Example 2\n",
      "Input: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Example 3\n",
      "Input: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Example 4\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "Continuation: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Example 5\n",
      "Input: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "\n",
      "Example 6\n",
      "Input: [0, 1]\n",
      "Continuation: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, input_sequence, max_length=15, sos_token=2, eos_token=3):\n",
    "    model.eval()\n",
    "    y_input = torch.tensor([[sos_token]], dtype=torch.long)\n",
    "    num_tokens = len(input_sequence[0])\n",
    "    for _ in range(max_length):\n",
    "        target_mask = get_target_mask(y_input.size(1))\n",
    "        pred = model(input_sequence, y_input, target_mask)\n",
    "        next_item = torch.tensor([[pred.topk(1)[1].reshape(-1)[-1].item()]])\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "        if next_item.reshape(-1).item() == eos_token:\n",
    "            break\n",
    "    return y_input.reshape(-1).tolist()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    torch.tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 3]], dtype=torch.long),\n",
    "    torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3]], dtype=torch.long),\n",
    "    torch.tensor([[2, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 3]], dtype=torch.long),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long),\n",
    "    torch.tensor([[2, 0, 1, 3]], dtype=torch.long),\n",
    "]\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"Input: {example.reshape(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49f396-229b-4c60-bbf2-b4e5c8da36c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromthetensor (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
