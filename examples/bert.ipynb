{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec11d5fe-ca07-4c42-b36b-59c1014c41d6",
   "metadata": {},
   "source": [
    "A rough copy of https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "\n",
    "Download dataset from https://www.kaggle.com/c/learn-ai-bbc/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6c8045-ddb0-4b6c-8d2d-b748a2403dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from helpers import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f36747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09ac9bf-59ad-4604-b522-30c6a2aff9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").resolve(strict=True).parent / \"data\"\n",
    "train_df = pd.read_csv(data_dir / \"BBC News Train.csv\")\n",
    "labels = {\"business\": 0, \"entertainment\": 1, \"sport\": 2, \"tech\": 3, \"politics\": 4}\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4c1db2-f642-4dae-8a57-7e598a5ba86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.labels = [labels[category] for category in data[\"Category\"]]\n",
    "        self.texts = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for text in data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], np.array(self.labels[idx])\n",
    "\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(768, 5)\n",
    "\n",
    "    def __call__(self, input_ids, mask):\n",
    "        _, output = self.bert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        output = self.fc(self.dropout(output)).relu()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fd0109-4d6a-41f9-a8cd-f38ef86900e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacky/repos/fromthetensor/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df = np.split(\n",
    "    train_df.sample(frac=1, random_state=1337), [int(0.8*len(train_df)), int(0.9*len(train_df))]\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(Dataset(train_df), batch_size=2, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(Dataset(valid_df), batch_size=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dab33-fb9e-4ede-922e-879042ca16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [03:07<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss 0.7920 | train accuracy 0.2802 | valid loss 0.7140 | valid accuracy 0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [03:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train loss 0.5085 | train accuracy 0.7659 | valid loss 0.3167 | valid accuracy 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [03:19<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | train loss 0.2334 | train accuracy 0.9664 | valid loss 0.1624 | valid accuracy 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [03:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | train loss 0.1338 | train accuracy 0.9790 | valid loss 0.1124 | valid accuracy 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [03:12<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | train loss 0.0836 | train accuracy 0.9908 | valid loss 0.0724 | valid accuracy 0.9799\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_train_loss = 0\n",
    "    total_train_correct = 0\n",
    "    for train_input, train_label in tqdm(train_dataloader):\n",
    "        mask = train_input[\"attention_mask\"].to(device)\n",
    "        input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        train_label = train_label.to(device)\n",
    "        loss = criterion(output, train_label.long())\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_correct += (output.argmax(dim=1) == train_label).sum().item()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_valid_loss = 0\n",
    "    total_valid_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for valid_input, valid_label in valid_dataloader:\n",
    "            mask = valid_input[\"attention_mask\"].to(device)\n",
    "            input_ids = valid_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            output = model(input_ids, mask)\n",
    "            valid_label = valid_label.to(device)\n",
    "            loss = criterion(output, valid_label.long())\n",
    "            total_valid_loss += loss.item()\n",
    "            total_valid_correct += (output.argmax(dim=1) == valid_label).sum().item()\n",
    "    print(\n",
    "        f\"epoch {epoch+1} | \"\n",
    "        f\"train loss {total_train_loss / len(train_df):.4f} | \"\n",
    "        f\"train accuracy {total_train_correct / len(train_df):.4f} | \"\n",
    "        f\"valid loss {total_valid_loss / len(valid_df):.4f} | \"\n",
    "        f\"valid accuracy {total_valid_correct / len(valid_df):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffefd81-dea0-42d0-b64c-3e34dd0dcf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9530\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(Dataset(test_df), batch_size=2)\n",
    "total_test_correct = 0\n",
    "with torch.no_grad():\n",
    "    for test_input, test_label in test_dataloader:\n",
    "        mask = test_input[\"attention_mask\"].to(device)\n",
    "        input_ids = test_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_ids, mask)\n",
    "        test_label = test_label.to(device)\n",
    "        total_test_correct += (output.argmax(dim=1) == test_label).sum().item()\n",
    "print(f\"test accuracy {total_test_correct / len(test_df):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaad836-35c8-451d-8c43-d6e6ebc0ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromthetensor (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
